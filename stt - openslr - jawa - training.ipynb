{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9ODlIw1BQJf"
      },
      "outputs": [],
      "source": [
        "%pip install jiwer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_RbMBmMBQJg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "# from tensorflow.keras import layers\n",
        "from keras import layers\n",
        "from jiwer import wer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9Rm0yY3BQJh"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXbmAqNXBQJh"
      },
      "outputs": [],
      "source": [
        "WAV_PATH = '/content/drive/MyDrive/datasetSpeechToText/audioJava500/wavs/'\n",
        "TSV_PATH = '/content/drive/MyDrive/datasetSpeechToText/audioJava500/line_indexEdited.tsv'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metadataDF = pd.read_csv(TSV_PATH, sep='\\t', header=None, quoting = 3)"
      ],
      "metadata": {
        "id": "KlPt8an1Edps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadataDF.tail(6)"
      ],
      "metadata": {
        "id": "HwQMVK8kEfq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadataDF.head(10)"
      ],
      "metadata": {
        "id": "g07IL-MbEf-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadataDF.columns = [\"file_name\", \"transcription\"]\n",
        "metadataDF = metadataDF[[\"file_name\", \"transcription\"]]\n",
        "metadataDF = metadataDF.sample(frac=1).reset_index(drop=True)\n",
        "metadataDF.head(6)"
      ],
      "metadata": {
        "id": "-0sJCmw6Ehhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiAATf25BQJi"
      },
      "outputs": [],
      "source": [
        "split = int(len(metadataDF) * 0.90)\n",
        "dfTrain = metadataDF[:split]\n",
        "dfVal = metadataDF[split:]\n",
        "\n",
        "print(f\"Size of the training set: {len(dfTrain)}\")\n",
        "print(f\"Size of the validation set: {len(dfVal)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GB_e2io4BQJi"
      },
      "outputs": [],
      "source": [
        "char = [x for x in \"abcdefghijklmnopqrstuvwxyz'?! \"]\n",
        "charToNum = keras.layers.StringLookup(vocabulary=char, oov_token=\"\")\n",
        "numToChar = keras.layers.StringLookup(vocabulary=charToNum.get_vocabulary(), oov_token=\"\", invert=True)\n",
        "\n",
        "print(f\"The Vocabulary size: {charToNum.get_vocabulary()}\")\n",
        "print(f\"(size = {charToNum.vocabulary_size()})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJ_cQr7MBQJi"
      },
      "outputs": [],
      "source": [
        "charToNum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0q6xuSHmBQJi"
      },
      "outputs": [],
      "source": [
        "frameLength = 256\n",
        "frameStep = 160\n",
        "fftLength = 384\n",
        "\n",
        "def encodeSingleSample(wavFile, label):\n",
        "    file = tf.io.read_file(WAV_PATH + wavFile + '.wav')\n",
        "    audio, _ = tf.audio.decode_wav(file)\n",
        "\n",
        "    audio = tf.squeeze(audio, axis=-1)\n",
        "    audio = tf.cast(audio, tf.float32)\n",
        "\n",
        "    spectogram = tf.signal.stft(audio, frame_length=frameLength, frame_step=frameStep, fft_length=fftLength)\n",
        "    spectogram = tf.abs(spectogram)\n",
        "    spectogram = tf.math.pow(spectogram, 0.5)\n",
        "\n",
        "    means = tf.math.reduce_mean(spectogram, 1, keepdims=True)\n",
        "    stddevs = tf.math.reduce_std(spectogram, 1, keepdims=True)\n",
        "    spectogram = (spectogram - means) / (stddevs + 1e-10)\n",
        "\n",
        "    label = tf.strings.lower(label)\n",
        "    label = tf.strings.unicode_split(label, input_encoding = 'UTF-8')\n",
        "    label = charToNum(label)\n",
        "\n",
        "    return spectogram, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIyjLwYSBQJi"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 4\n",
        "\n",
        "trainDataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (list(dfTrain['file_name']), list(dfTrain['transcription']))\n",
        ")\n",
        "trainDataset = (\n",
        "    trainDataset.map(encodeSingleSample, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .padded_batch(BATCH_SIZE)\n",
        "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "valDataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (list(dfVal['file_name']), list(dfVal['transcription']))\n",
        ")\n",
        "valDataset = (\n",
        "    valDataset.map(encodeSingleSample, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .padded_batch(BATCH_SIZE)\n",
        "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dd-oqUSoBQJj"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10, 10))\n",
        "for batch in trainDataset.take(1):\n",
        "    spectogram = batch[0][0].numpy()\n",
        "    spectogram = np.array([np.trim_zeros(x) for x in np.transpose(spectogram)])\n",
        "    label = batch[1][0]\n",
        "\n",
        "    label = tf.strings.reduce_join(numToChar(label)).numpy().decode('utf-8')\n",
        "    ax = fig.add_subplot(2,1,1)\n",
        "    ax.imshow(spectogram, vmax=1)\n",
        "    ax.set_title(label)\n",
        "    ax.axis('off')\n",
        "\n",
        "    file = tf.io.read_file(WAV_PATH + dfTrain['file_name'][0] + '.wav')\n",
        "    audio, _ = tf.audio.decode_wav(file)\n",
        "    audio = audio.numpy()\n",
        "    ax = fig.add_subplot(2,1,2)\n",
        "    ax.plot(audio)\n",
        "    ax.set_title(\"Signal Wave\")\n",
        "    ax.set_xlim([0, len(audio)])\n",
        "    display.display(display.Audio(np.transpose(audio), rate=16000))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVFcxaRmBQJj"
      },
      "outputs": [],
      "source": [
        "def CTCLoss (y_true, y_pred):\n",
        "    batchLen = tf.cast(tf.shape(y_true)[0], dtype='int64')\n",
        "    inputLen = tf.cast(tf.shape(y_pred)[1], dtype='int64')\n",
        "    labelLen = tf.cast(tf.shape(y_true)[1], dtype='int64')\n",
        "\n",
        "    inputLen = inputLen * tf.ones(shape=(batchLen, 1), dtype='int64')\n",
        "    labelLen = labelLen * tf.ones(shape=(batchLen, 1), dtype='int64')\n",
        "\n",
        "    loss = keras.backend.ctc_batch_cost(y_true, y_pred, inputLen, labelLen)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFg-qXMYBQJj"
      },
      "outputs": [],
      "source": [
        "def buildModel(inputDim, outputDim, rnnLayers = 5, rnnUnits = 128):\n",
        "    inputSpectogram = layers.Input((None, inputDim), name='input')\n",
        "\n",
        "    # Expand Dimension to use 2D CNN\n",
        "    x = layers.Reshape((-1, inputDim, 1), name = \"expandDim\")(inputSpectogram)\n",
        "\n",
        "    # Convolution Layer 1\n",
        "    x = layers.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=[11, 41],\n",
        "        strides=[2, 2],\n",
        "        padding='same',\n",
        "        use_bias=False,\n",
        "        name='conv_1'\n",
        "    )(x)\n",
        "    x = layers.BatchNormalization(name='conv_1_bn')(x)\n",
        "    x = layers.ReLU(name='conv_1_relu')(x)\n",
        "\n",
        "    # Convolution Layer 2\n",
        "    x = layers.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=[11, 21],\n",
        "        strides=[1, 2],\n",
        "        padding='same',\n",
        "        use_bias=False,\n",
        "        name='conv_2'\n",
        "    )(x)\n",
        "    x = layers.BatchNormalization(name='conv_2_bn')(x)\n",
        "    x = layers.ReLU(name='conv_2_relu')(x)\n",
        "\n",
        "    # Reshape the resulted volume to feed the RNN's layers\n",
        "    x = layers.Reshape((-1, x.shape[2] * x.shape[-1]))(x)\n",
        "\n",
        "    # RNN Layers\n",
        "    for i in range (1, rnnLayers + 1):\n",
        "        recurrent = layers.GRU(\n",
        "            units=rnnUnits,\n",
        "            activation='tanh',\n",
        "            recurrent_activation='sigmoid',\n",
        "            use_bias=True,\n",
        "            return_sequences=True,\n",
        "            reset_after=True,\n",
        "            name=f'gru_{i}'\n",
        "        )\n",
        "        x = layers.Bidirectional(recurrent, name=f'bidirectional_{i}', merge_mode=\"concat\")(x)\n",
        "        if i < rnnLayers:\n",
        "            x = layers.Dropout(rate = 0.5)(x)\n",
        "\n",
        "    # Dense Layer\n",
        "    x = layers.Dense(units = rnnUnits * 2, name = \"dense_1\")(x)\n",
        "    x = layers.ReLU(name = \"dense_1_relu\")(x)\n",
        "    x = layers.Dropout(rate = 0.5)(x)\n",
        "\n",
        "    # Classification Layer\n",
        "    output = layers.Dense(units = outputDim + 1, activation = \"softmax\")(x)\n",
        "\n",
        "    # Model\n",
        "    model = keras.Model(inputs = inputSpectogram, outputs = output, name = \"DeepSpeech2\")\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = keras.optimizers.Adam(learning_rate = 1e-4)\n",
        "\n",
        "    # Compile\n",
        "    model.compile(optimizer = optimizer, loss = CTCLoss)\n",
        "\n",
        "    return model\n",
        "\n",
        "model = buildModel(inputDim = fftLength // 2 + 1, outputDim = charToNum.vocabulary_size(), rnnUnits = 512)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMl4re0VBQJj"
      },
      "outputs": [],
      "source": [
        "def decodeBatchPredictions(pred):\n",
        "    inputLen = np.ones(pred.shape[0]) * pred.shape[1]\n",
        "    results = keras.backend.ctc_decode(pred, input_length=inputLen, greedy=True)[0][0]\n",
        "    outputText = []\n",
        "    for result in results:\n",
        "        result = tf.strings.reduce_join(numToChar(result)).numpy().decode('utf-8')\n",
        "        outputText.append(result)\n",
        "    return outputText\n",
        "\n",
        "class CallbackEval(keras.callbacks.Callback):\n",
        "    def __init__(self, dataset):\n",
        "        super().__init__()\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        predictions = []\n",
        "        targets = []\n",
        "\n",
        "        for batch in self.dataset:\n",
        "            X, y = batch\n",
        "            batchPredictions = model.predict(X)\n",
        "            batchPredictions = decodeBatchPredictions(batchPredictions)\n",
        "            predictions.extend(batchPredictions)\n",
        "            for label in y:\n",
        "                label = (\n",
        "                    tf.strings.reduce_join(numToChar(label)).numpy().decode('utf-8')\n",
        "                )\n",
        "                targets.append(label)\n",
        "        werScore = wer(targets, predictions)\n",
        "        print(\"-\" * 50)\n",
        "        print(f\"Word Error Rate: {werScore:.4f}\")\n",
        "        print(\"-\" * 50)\n",
        "        for i in np.random.randint(0, len(predictions), 5):\n",
        "            print(f\"Target    : {targets[i]}\")\n",
        "            print(f\"Prediction: {predictions[i]}\")\n",
        "            print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7in98nyOBQJj"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 135\n",
        "valCallBack = CallbackEval(valDataset)\n",
        "history = model.fit(trainDataset, validation_data=valDataset, epochs=EPOCHS, callbacks=[valCallBack])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUiLG55jBQJj"
      },
      "outputs": [],
      "source": [
        "# save the models to disk\n",
        "model.save('model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjxNuaTJBQJk"
      },
      "outputs": [],
      "source": [
        "predictions = []\n",
        "targets = []\n",
        "for batch in valDataset:\n",
        "    X, y = batch\n",
        "    batchPredictions = model.predict(X)\n",
        "    batchPredictions = decodeBatchPredictions(batchPredictions)\n",
        "    predictions.extend(batchPredictions)\n",
        "    for label in y:\n",
        "        label = (\n",
        "            tf.strings.reduce_join(numToChar(label)).numpy().decode('utf-8')\n",
        "        )\n",
        "        targets.append(label)\n",
        "werScore = wer(targets, predictions)\n",
        "print(\"-\" * 50)\n",
        "print(f\"Word Error Rate: {werScore:.4f}\")\n",
        "print(\"-\" * 50)\n",
        "for i in np.random.randint(0, len(predictions), 5):\n",
        "    print(f\"Target    : {targets[i]}\")\n",
        "    print(f\"Prediction: {predictions[i]}\")\n",
        "    print(\"-\" * 50)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}